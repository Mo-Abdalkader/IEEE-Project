{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24408d3",
   "metadata": {},
   "source": [
    "### Packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf16c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install easygui\n",
    "# pip install prettytable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda3378",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0439be61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Decisiond tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics \n",
    "\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Clustring\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Hierarchical clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# GUI\n",
    "from tkinter import * \n",
    "from easygui import *\n",
    "\n",
    "# visualisation\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk)\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# more\n",
    "from prettytable import PrettyTable\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import easygui\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e8912",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1674fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def open_file_dialog(warning = \"Please select only CSV file\"):\n",
    "    try:\n",
    "        return easygui.fileopenbox()\n",
    "    except:\n",
    "        return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ef78b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_frame():\n",
    "    return pd.read_csv(open_file_dialog())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6f1e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_text_widget(message , title = \"\", text = \"\"):\n",
    "    return textbox(message, title, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc39433d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_text_choise(choices , text=\"Please selecte only one item.\",title = \"Choise box\"):\n",
    "    return choicebox(text, title, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b291ae22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_message_box(message , title=\"Message Box\"):\n",
    "    return msgbox(message, title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab674ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_data(data_frame , scale_type = \"min_max\"):\n",
    "    if scale_type == \"min_max\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scale_type == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "    scal = scaler.fit(data_frame)\n",
    "    return scal.transform(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7351e324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_splitted_data(x , y):\n",
    "    x_train , x_test , y_train , y_test = train_test_split( x , y , test_size = 0.25 ,  random_state=50 )\n",
    "    return x_train , x_test , y_train , y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188a3aa",
   "metadata": {},
   "source": [
    "### 1- Supervised machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490097e7",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f47387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model2 = LogisticRegression()\n",
    "    model2.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    train_pred = model2.predict(x_train_sc)\n",
    "    test_pred = model2.predict(x_test_sc)\n",
    "\n",
    "    train_score = metrics.accuracy_score( train_pred , y_train_sc )\n",
    "    test_score = metrics.accuracy_score( test_pred , y_test_sc )\n",
    "\n",
    "    logistic_regression_score = f\"{'Logistic regression score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "\n",
    "    return logistic_regression_score ,\"Logistic regression\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fff2b",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a65f162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def linear_regression(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    train_score = model.score(x_train_sc , y_train_sc) \n",
    "    test_score = model.score(x_test_sc , y_test_sc) \n",
    "    \n",
    "    linear_regression_score = f\"{'Linear regression score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return linear_regression_score ,\"Linear regression\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263d6d8",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3afe3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def k_neighbor(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model3 = KNeighborsClassifier()\n",
    "    model3.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    tr_pred = model3.predict(x_train_sc)\n",
    "    te_pred = model3.predict(x_test_sc)\n",
    "\n",
    "    train_score = metrics.accuracy_score(tr_pred,y_train_sc)\n",
    "    test_score = metrics.accuracy_score(te_pred,y_test_sc)\n",
    "\n",
    "    knn_score = f\"{'KNeighbors score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    \n",
    "    return knn_score ,\"KNeighbors\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e54ce",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42782a26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def neural_network(x_train , x_test , y_train, y_test , is_continuous = True ):\n",
    "    if is_continuous:\n",
    "        model4 = MLPRegressor(hidden_layer_sizes=(100,),\n",
    "                              activation='relu',\n",
    "                              solver='adam',\n",
    "                              alpha=0.001,\n",
    "                              batch_size='auto',\n",
    "                              learning_rate='constant',\n",
    "                              learning_rate_init=0.001,\n",
    "                              power_t=0.5,\n",
    "                              max_iter=200,\n",
    "                              shuffle=True,\n",
    "                              random_state=None,\n",
    "                              tol=0.0001,\n",
    "                              verbose=False,\n",
    "                              warm_start=False,\n",
    "                              momentum=0.9,\n",
    "                              nesterovs_momentum=True,\n",
    "                              early_stopping=False,\n",
    "                              validation_fraction=0.1,\n",
    "                              beta_1=0.9,\n",
    "                              beta_2=0.999,\n",
    "                              epsilon=1e-08,\n",
    "                              n_iter_no_change=10,\n",
    "                              max_fun=15000)\n",
    "\n",
    "#         model4 = MLPRegressor(activation='relu',\n",
    "#                                solver='adam',\n",
    "#                                learning_rate='constant',\n",
    "#                                early_stopping=False,\n",
    "#                                alpha=0.0001, hidden_layer_sizes=(100, 3), random_state = 33)\n",
    "        model4.fit(x_train, y_train)\n",
    "\n",
    "    else:\n",
    "        model4 = MLPClassifier(activation='tanh',\n",
    "                               solver='lbfgs',\n",
    "                               learning_rate='constant',\n",
    "                               early_stopping=False,\n",
    "                               alpha=0.001, hidden_layer_sizes=(100, 3), random_state = 33)\n",
    "        model4.fit(x_train, y_train)\n",
    "\n",
    "    train_score = model4.score(x_train, y_train)\n",
    "    test_score = model4.score(x_test, y_test)\n",
    "\n",
    "    neural_network_score = f\"{'Neural network score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    # scores[\"neural_network_score\"] = neural_network_score\n",
    "    \n",
    "    return neural_network_score ,\"Neural network\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f41c1",
   "metadata": {},
   "source": [
    "#### Decisiond tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c18afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decisiond_tree(x_train_sc , x_test_sc , y_train_sc , y_test_sc , is_continuous = True):\n",
    "    if is_continuous:\n",
    "        model5 = DecisionTreeRegressor( max_depth = 3)\n",
    "        \n",
    "    else:\n",
    "        model5 = DecisionTreeClassifier( max_depth = 3)\n",
    "        \n",
    "    model5.fit(x_train_sc,y_train_sc)\n",
    "    train_score = model5.score( x_train_sc , y_train_sc )\n",
    "    test_score = model5.score( x_test_sc , y_test_sc )\n",
    "\n",
    "    decision_tree_score = f\"{'Decision tree score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    \n",
    "    return decision_tree_score ,\"Decision tree\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9d9a3",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c92ec51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def svm(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    \n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                  'kernel': ['rbf'] }\n",
    "    \n",
    "    ###################################################\n",
    "    # grid = GridSearchCV(SVC(), param_grid)\n",
    "    # grid.fit(x_train_sc, y_train_sc)\n",
    "    # grid_predictions = grid.predict(x_test_sc)\n",
    "    # metrics.accuracy_score(grid_predictions,y_test_sc)\n",
    "    \n",
    "    ##################################################\n",
    "    \n",
    "    model6 = SVC()\n",
    "    model6.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    train_predictions = model6.predict(x_train_sc)\n",
    "    test_predictions = model6.predict(x_test_sc)\n",
    "    \n",
    "    model6.get_params()\n",
    "    \n",
    "    train_score = metrics.accuracy_score(train_predictions,y_train_sc) \n",
    "    test_score = metrics.accuracy_score(test_predictions,y_test_sc)\n",
    "    \n",
    "    svm_score = f\"{'SVM score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return svm_score ,\"SVM\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6ed4e",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8646bcda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_forest(x_train_sc , x_test_sc , y_train_sc , y_test_sc , is_continuous = True):\n",
    "        \n",
    "    if is_continuous:\n",
    "        model7 = RandomForestRegressor(n_estimators = 20 , random_state = 30)\n",
    "        model7.fit(x_train_sc,y_train_sc)\n",
    "\n",
    "        train_score = model7.score(x_train_sc,y_train_sc)\n",
    "        test_score = model7.score(x_test_sc,y_test_sc)\n",
    "\n",
    "        random_forest = f\"{'Random forest'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "\n",
    "        return random_forest ,\"Random forest\" , train_score , test_score\n",
    "\n",
    "    else:\n",
    "        model7 = RandomForestClassifier(n_estimators = 20 , random_state = 30)\n",
    "        \n",
    "        model7.fit(x_train_sc,y_train_sc)\n",
    "\n",
    "        prediction_train = model7.predict(x_train_sc)\n",
    "        train_score = metrics.accuracy_score(y_train_sc, prediction_train)\n",
    "\n",
    "        prediction_test = model7.predict(x_test_sc)\n",
    "        test_score = metrics.accuracy_score(y_test_sc, prediction_test)\n",
    "\n",
    "        random_forest = f\"{'Random forest'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "\n",
    "        return random_forest ,\"Random forest\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a6f0d",
   "metadata": {},
   "source": [
    "#### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ab906e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes(x_train,x_test, y_train, y_test):\n",
    "    model8 = GaussianNB()\n",
    "    model8.fit(x_train,y_train)\n",
    "\n",
    "    train_score = model8.score(x_train , y_train)\n",
    "    test_score = model8.score(x_test , y_test)\n",
    "\n",
    "    naive_baise_score = f\"{'Naive bayes'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return naive_baise_score ,\"Naive bayes\" , train_score , test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee702b",
   "metadata": {},
   "source": [
    "### Unsupervised machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d820143",
   "metadata": {},
   "source": [
    "#### Clustring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a574d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def default_cluster(data_frame):\n",
    "    error=[]\n",
    "    k_range=range(1,18)\n",
    "    for k in k_range:\n",
    "        km = KMeans(n_clusters=k)\n",
    "        km.fit(data_frame) \n",
    "        error.append(km.inertia_)\n",
    "    def plot():\n",
    "            fig = Figure(figsize = (30, 30),dpi = 100)\n",
    "            plot1= fig.add_subplot(111)\n",
    "            plot1.plot(k_range,error)\n",
    "            canvas = FigureCanvasTkAgg(fig, master = window)  \n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack()\n",
    "            toolbar = NavigationToolbar2Tk(canvas, window)\n",
    "            toolbar.update()\n",
    "            canvas.get_tk_widget().pack()\n",
    "    window = Tk()\n",
    "    window.title('What is the best number of clusters?')\n",
    "    window.geometry(\"500x500\")\n",
    "    plot_button = Button(master = window, \n",
    "                     command = plot,\n",
    "                     height = 2, \n",
    "                     width = 10,\n",
    "                     text = \"Plot\")\n",
    "    plot_button.pack()\n",
    "    window.mainloop()\n",
    "    \n",
    "    quetsion = get_text_choise(choices = ['Yes','No'] ,text=\"Is the graph have Elbow shape and near to x_axis?\")\n",
    "   \n",
    "    if quetsion == 'Yes':\n",
    "            num_of_clusters = int(get_text_widget(\"Enter num of clusters\"))\n",
    "            km = KMeans(n_clusters = num_of_clusters)\n",
    "            y = km.fit_predict(data_frame)\n",
    "            y = pd.DataFrame(y)\n",
    "            data_frame = pd.DataFrame(data_frame)\n",
    "            data_frame['y'] = y \n",
    "            file_path = get_text_widget(\"Enter you directory path!\")\n",
    "            data_frame.to_csv(file_path + \"\\\\\" + \"csv_test_file\" + \".csv\")\n",
    "            return None\n",
    "    elif quetsion =='No':\n",
    "        # if no go to clustering function\n",
    "            clustering(data_frame)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcedc3ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clustering(data_frame):\n",
    "    cluster_items = ['output has 0,1 values',\n",
    "                     'output has more than two values']\n",
    "    item = get_text_choise(choices = cluster_items)\n",
    "    if item == 'output has 0,1 values':\n",
    "        error = []\n",
    "        k_range=range(1,3)\n",
    "        for k in k_range:\n",
    "            km = KMeans(n_clusters=k)\n",
    "            km.fit(data_frame) \n",
    "            error.append(km.inertia_)\n",
    "        km = KMeans(n_clusters=2)\n",
    "        y = km.fit_predict(data_frame)\n",
    "        y = pd.DataFrame(y)\n",
    "        data_frame = pd.DataFrame(data_frame)\n",
    "        data_frame['y'] = y \n",
    "        file_path = get_text_widget(\"Enter you directory path!\")\n",
    "        data_frame.to_csv(file_path + \"\\\\\" + \"csv_test_file\" + \".csv\")\n",
    "        \n",
    "    elif item == 'output has more than two values':\n",
    "        num_of_k_range=int(get_text_widget(\"Enter num of K_range\"))\n",
    "        error = []\n",
    "        k_range = range(1,num_of_k_range)\n",
    "        \n",
    "        for k in k_range:\n",
    "            km = KMeans(n_clusters = k)\n",
    "            km.fit(data_frame) \n",
    "            error.append(km.inertia_)\n",
    "            \n",
    "        def plot():\n",
    "            fig = Figure(figsize = (30, 30),dpi = 100)\n",
    "            plot1= fig.add_subplot(111)\n",
    "            plot1.plot(k_range,error)\n",
    "            canvas = FigureCanvasTkAgg(fig, master = window)  \n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack()\n",
    "            toolbar = NavigationToolbar2Tk(canvas, window)\n",
    "            toolbar.update()\n",
    "            canvas.get_tk_widget().pack()\n",
    "            \n",
    "        window = Tk()\n",
    "        window.title('Plotting in Tkinter')\n",
    "        window.geometry(\"500x500\")\n",
    "        plot_button = Button(master = window, \n",
    "                     command = plot,\n",
    "                     height = 2, \n",
    "                     width = 10,\n",
    "                     text = \"Plot\")\n",
    "        plot_button.pack()\n",
    "        window.mainloop()\n",
    "        \n",
    "        num_of_clusters = int(get_text_widget(\"Enter num of clusters\"))\n",
    "        km = KMeans(n_clusters = num_of_clusters)\n",
    "        y = km.fit_predict(data_frame)\n",
    "        y = pd.DataFrame(y)\n",
    "        data_frame = pd.DataFrame(data_frame)\n",
    "        data_frame['y'] = y \n",
    "        file_path = get_text_widget(\"Enter you directory path!\")\n",
    "        data_frame.to_csv(file_path + \"\\\\\" + \"csv_test_file\" + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af2a5f",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd2a2c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Hierarchical_clustering(data_frame):\n",
    "    def plot():\n",
    "            fig=plt.figure(figsize = (10 ,6))\n",
    "            linkage_data = linkage(data_frame, method='ward', metric='euclidean')\n",
    "            dendrogram(linkage_data)\n",
    "            plt.show()\n",
    "            canvas = FigureCanvasTkAgg(fig, master = window)  \n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack()\n",
    "            toolbar = NavigationToolbar2Tk(canvas, window)\n",
    "            toolbar.update()\n",
    "            canvas.get_tk_widget().pack()\n",
    "    window = Tk()\n",
    "    window.title('Plot')\n",
    "    window.geometry(\"500x500\")\n",
    "    plot_button = Button(master = window, \n",
    "                     command = plot,\n",
    "                     height = 2, \n",
    "                     width = 10,\n",
    "                     text = \"Plot\")\n",
    "    plot_button.pack()\n",
    "    window.mainloop()\n",
    "    clusters_num=int(get_text_widget(\"enter num of clusters according to hierarchal graph\"))\n",
    "    model = AgglomerativeClustering(n_clusters =clusters_num, affinity = 'euclidean', linkage ='ward')\n",
    "    y_model = model.fit_predict(data_frame)\n",
    "    data_frame['cluster'] = pd.DataFrame(y_model)\n",
    "    file_path = get_text_widget(\"Enter you directory path!\")\n",
    "    data_frame.to_csv(file_path + \"\\\\\" + \"csv_test_file\" + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888f240",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd72b5",
   "metadata": {},
   "source": [
    "#### Create your data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b16cd6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your csv file to create the dataframe directly , If you have not any data frame ready to be used this \n",
    "counter = 1\n",
    "data_frame = None\n",
    "def load_data_frame():\n",
    "    try:\n",
    "        global data_frame\n",
    "        data_frame = get_data_frame()\n",
    "        return True\n",
    "    except:\n",
    "        global counter\n",
    "        if counter % 4 != 0:\n",
    "            counter += 1\n",
    "            if get_message_box(\"Please select olny preproccessed csv file to avoid errors!\") == \"OK\":\n",
    "                load_data_frame()\n",
    "            else:\n",
    "                try:\n",
    "                    sys.exit()\n",
    "                except:\n",
    "                    print(\"System exitted\")\n",
    "        else:\n",
    "            get_message_box(\"You were warned to select only csv files :) \")\n",
    "            return False\n",
    "# We calculate how many you will choose the wrong file, \n",
    "# so that I can close the program so that it does not fall into infinity loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "818dbec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run():    \n",
    "\n",
    "    ml_type = get_text_choise(choices=[\"Supervised\",\"Unsupervised\"])\n",
    "    if ml_type == \"Supervised\":\n",
    "\n",
    "        prediction_type = get_text_choise(choices=[\"Predict continuous value\",\"Predict discrete value\"])\n",
    "        if prediction_type == \"Predict continuous value\":\n",
    "\n",
    "            if (not load_data_frame()):\n",
    "                get_message_box(\"May be you break one of these rules\\n\\n1- You did not select a csv file \\n2- You closed the window without selecting any files \\n3- You selected csv file contains raw data without preproccessing \\n\\n\\nSo the program will be closed \\nعشان تبقى تسمع الكلام:) \")\n",
    "                run()\n",
    "            supervised_models_list = [\n",
    "                \"Linear regression\",\n",
    "                \"Neural network\",\n",
    "                \"Decisiond tree\",\n",
    "                \"Random forest\",\n",
    "                \"All models\",\n",
    "                \"Back\"\n",
    "            ]\n",
    "            supervised_model = get_text_choise(supervised_models_list)\n",
    "\n",
    "            y = data_frame[data_frame.columns[-1]]\n",
    "            x = data_frame.drop(data_frame.columns[-1],axis=1)\n",
    "\n",
    "            x_train , x_test , y_train , y_test = get_splitted_data(x,y)\n",
    "\n",
    "            x = get_scaled_data(x)\n",
    "\n",
    "            x_trainsc , x_testsc , y_trainsc , y_testsc = get_splitted_data(x,y)\n",
    "\n",
    "            try:\n",
    "                index_of_model = supervised_models_list.index(supervised_model)\n",
    "                print(\"index_of_model\",index_of_model)\n",
    "\n",
    "                if index_of_model == 0:\n",
    "                    score = linear_regression(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "                elif index_of_model == 1:\n",
    "                    score = neural_network(x_trainsc , x_testsc , y_trainsc , y_testsc , True)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "                elif index_of_model == 2:\n",
    "                    score = decisiond_tree(x_trainsc , x_testsc , y_trainsc , y_testsc , True)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 3:\n",
    "                    score = random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc,True)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 4:\n",
    "                    scores = list()\n",
    "                    scores.append(linear_regression(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "                    scores.append(neural_network(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "                    scores.append(decisiond_tree(x_train , x_test , y_train , y_test))                                               \n",
    "                    scores.append(random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc))                        \n",
    "\n",
    "#                         score = scores[0][0] +\"\\n\"+ scores[1][0] +\"\\n\"+ scores[2][0] +\"\\n\"+ scores[3][0] +\"\\n\"+ scores[4][0] +\"\\n\"+ scores[5][0] +\"\\n\"+ scores[6][0]\n",
    "#                         print(score)\n",
    "#                         get_message_box(score)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    for counter in range(len(scores)):\n",
    "                        table.add_row([scores[counter][1],f\"{round(scores[counter][2] * 100,3)}%\",f\"{round(scores[counter][3] * 100,3)}%\"])\n",
    "                        table.add_row([\"\",\"\",\"\"])\n",
    "                    get_message_box(table)\n",
    "                    print(table)\n",
    "\n",
    "                    return run()\n",
    "                elif index_of_model == 6:\n",
    "                    return run()\n",
    "                else:\n",
    "                    get_message_box(\"The program will be closed :) \")\n",
    "                    sys.exit()\n",
    "            except:\n",
    "                try:\n",
    "                    sys.exit()\n",
    "                except:\n",
    "                    print(\"The program has been colsed!\")\n",
    "\n",
    "        elif prediction_type == \"Predict discrete value\":\n",
    "            is_continuous = False\n",
    "            if (not load_data_frame()):\n",
    "                get_message_box(\"May be you break one of these rules\\n\\n1- You did not select a csv file \\n2- You closed the window without selecting any files \\n3- You selected csv file contains raw data without preproccessing \\n\\n\\nSo the program will be closed \\nعشان تبقى تسمع الكلام:) \")\n",
    "                sys.exit()\n",
    "            supervised_models_list = [\n",
    "                \"Logistic regression\",\n",
    "                \"KNN\",\n",
    "                \"Neural network\",\n",
    "                \"Decisiond tree\",\n",
    "                \"SVM\",\n",
    "                \"Random forest\",\n",
    "                \"Naive bayes\",\n",
    "                \"All models\",\n",
    "                \"Back\"\n",
    "            ]\n",
    "            supervised_model = get_text_choise(supervised_models_list)\n",
    "\n",
    "            y = data_frame[data_frame.columns[-1]]\n",
    "            x = data_frame.drop(data_frame.columns[-1],axis=1)\n",
    "\n",
    "            x_train , x_test , y_train , y_test = get_splitted_data(x,y)\n",
    "\n",
    "            x = get_scaled_data(x)\n",
    "\n",
    "            x_trainsc , x_testsc , y_trainsc , y_testsc = get_splitted_data(x,y)\n",
    "\n",
    "            try:\n",
    "                index_of_model = supervised_models_list.index(supervised_model)\n",
    "                print(\"index_of_model\",index_of_model)\n",
    "\n",
    "                if index_of_model == 0:\n",
    "                    score = logistic_regression(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 1:\n",
    "                    score = k_neighbor(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 2:\n",
    "                    score = neural_network(x_trainsc , x_testsc , y_trainsc , y_testsc, is_continuous)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 3:\n",
    "                    score = decisiond_tree(x_trainsc , x_testsc , y_trainsc , y_testsc , is_continuous)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 4:\n",
    "                    score = svm(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 5:\n",
    "\n",
    "                    score = random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc , is_continuous)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 6:\n",
    "                    score = naive_bayes(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    table.add_row([score[1],f\"{round(score[2] * 100,3)}%\",f\"{round(score[3] * 100,3)}%\"])\n",
    "                    get_message_box(table)\n",
    "\n",
    "                    return run()\n",
    "\n",
    "                elif index_of_model == 7:\n",
    "\n",
    "                    scores = list()\n",
    "\n",
    "                    scores.append(logistic_regression(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "                    scores.append(k_neighbor(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "                    scores.append(neural_network(x_train , x_test , y_train , y_test , is_continuous))\n",
    "                    scores.append(decisiond_tree(x_train , x_test , y_train , y_test , is_continuous))\n",
    "                    scores.append(svm(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "                    scores.append(random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc , is_continuous))\n",
    "                    scores.append(naive_bayes(x_trainsc , x_testsc , y_trainsc , y_testsc))\n",
    "\n",
    "#                         score = scores[0][0] +\"\\n\"+ scores[1][0] +\"\\n\"+ scores[2][0] +\"\\n\"+ scores[3][0] +\"\\n\"+ scores[4][0] +\"\\n\"+ scores[5][0] +\"\\n\"+ scores[6][0]\n",
    "#                         print(score)\n",
    "#                         get_message_box(score)\n",
    "\n",
    "                    table = PrettyTable([\"Algorithm name\",\"Train score\",\"Test score\"])\n",
    "                    for counter in range(len(scores)):\n",
    "                        table.add_row([scores[counter][1],f\"{round(scores[counter][2] * 100,3)}%\",f\"{round(scores[counter][3] * 100,3)}%\"])\n",
    "#                             table.add_row([\"\",\"\",\"\"])\n",
    "                    get_message_box(table)\n",
    "                    print(table)\n",
    "                    \n",
    "                    return run()\n",
    "                elif index_of_model ==8:\n",
    "                    return run()\n",
    "                else:\n",
    "                    get_message_box(\"The program will be closed :) \")\n",
    "                    sys.exit()\n",
    "            except:\n",
    "                exit()    \n",
    "        else:\n",
    "            return run()\n",
    "    elif ml_type == \"Unsupervised\":\n",
    "        if (not load_data_frame()):\n",
    "            get_message_box(\"The program will be closed :) \")\n",
    "            sys.exit()\n",
    "\n",
    "        unsupervised_models_list = [\"Cluster\",\"Hierarchal cluster\"]\n",
    "        unsupervised_model = get_text_choise(unsupervised_models_list)\n",
    "\n",
    "        try:\n",
    "            index_of_model = unsupervised_models_list.index(unsupervised_model)\n",
    "            print(\"index_of_model\",index_of_model)\n",
    "\n",
    "            if index_of_model == 0:\n",
    "                default_cluster(data_frame)\n",
    "\n",
    "                return run()\n",
    "            elif index_of_model == 1:\n",
    "                Hierarchical_clustering(data_frame)\n",
    "\n",
    "                return run()\n",
    "            else:\n",
    "                return run()\n",
    "        except:\n",
    "            exit() \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097fa0d",
   "metadata": {},
   "source": [
    "#### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc6628d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_of_model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohamed\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+------------+\n",
      "|    Algorithm name   | Train score | Test score |\n",
      "+---------------------+-------------+------------+\n",
      "| Logistic regression |   95.305%   |  96.503%   |\n",
      "|      KNeighbors     |   97.887%   |  95.804%   |\n",
      "|    Neural network   |   92.254%   |   90.21%   |\n",
      "|    Decision tree    |   96.714%   |   90.21%   |\n",
      "|         SVM         |   98.592%   |  97.203%   |\n",
      "|    Random forest    |   99.765%   |  96.503%   |\n",
      "|     Naive bayes     |   94.131%   |  92.308%   |\n",
      "+---------------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be8a02",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f32914",
   "metadata": {},
   "source": [
    "#### Used dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504eb09a",
   "metadata": {},
   "source": [
    "https://github.com/Mo-Abdalkader/IEEE-Project/blob/main/Breast-cancer%20preprocessed_file.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
