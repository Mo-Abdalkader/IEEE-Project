{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b24408d3",
   "metadata": {},
   "source": [
    "#### Libraries installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf16c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install easygui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda3378",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0439be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import easygui \n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e8912",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b15d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_path(download_folder_path , dataset_kaggle_path):\n",
    "    return fr\"{download_folder_path}/{str(dataset_kaggle_path).split('/')[-1]}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1674fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_dialog(warning = \"Please select only CSV file\"):\n",
    "    try:\n",
    "        return easygui.fileopenbox()\n",
    "    except:\n",
    "        return warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ef78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frame():\n",
    "    return pd.read_csv(open_file_dialog())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6f1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easygui import *\n",
    "\n",
    "def get_text_widget(message , title = \"\", text = \"\"):\n",
    "    return textbox(message, title, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc39433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easygui import *\n",
    "\n",
    "def get_text_choise(choices , text=\"Please selecte only one item.\",title = \"Choise box\"):\n",
    "    return choicebox(text, title, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b291ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_box(message , title=\"Message Box\"):\n",
    "    return msgbox(message, title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ab197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab674ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def get_scaled_data(data_frame):\n",
    "    scaler = MinMaxScaler()\n",
    "    scal = scaler.fit(data_frame)\n",
    "    return scal.transform(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7351e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitted_data(x , y = None , model_type =\"Supervised\"):\n",
    "    if model_type == \"Supervised\":\n",
    "#         x = data_frame.drop([data_frame.columns[-1]],axis=1)\n",
    "#         y = data_frame[data_frame.columns[-1]]\n",
    "\n",
    "#         x_scale = data_scaling(data_frame.drop([data_frame.columns[-1]],axis=1))\n",
    "\n",
    "        x_train , x_test , y_train , y_test = train_test_split( x , y , test_size = 0.25 ,  random_state=50,stratify=y)\n",
    "        return x_train , x_test , y_train , y_test\n",
    "    elif model_type == \"Unsupervised\":\n",
    "        return data_scaling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373befe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a97fcd43",
   "metadata": {},
   "source": [
    "# Part 1 : Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81fd1f",
   "metadata": {},
   "source": [
    "### Connectting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91055e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f500f",
   "metadata": {},
   "source": [
    "### Dataset search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492e088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kagggle_dataset(kaggle_message = \"Enter needed dataset name!\"):\n",
    "    # Enter your dataset name --------> GUI\n",
    "    dataset_needed = get_text_widget(kaggle_message,\"Kaggle database\",\"\")\n",
    "    if dataset_needed == \"\"  or dataset_needed.strip() == \"\":\n",
    "        kagggle_dataset(f\"There is no empty dataset! \\n\\nEnter another dataset name!\")\n",
    "        return None\n",
    "    elif dataset_needed == None:\n",
    "        return None\n",
    "    try:    \n",
    "        datasets_founded_list = api.dataset_list(search = dataset_needed , file_type = \"csv\")[:]\n",
    "\n",
    "        all_datasets_founded = \"\"\n",
    "        all_datasets_founded_list = list()\n",
    "        \n",
    "        for index , dataset_founded in enumerate(datasets_founded_list , 1):\n",
    "            size = api.datasets_list(search = str(dataset_founded))[0][\"totalBytes\"]\n",
    "            all_datasets_founded = f\"{str(index).rjust(2,'0')}- {str(datasets_founded_list[index-1]).ljust(70)}  | size -> {(str(size)+' Bytes').rjust(20)} \"\n",
    "            all_datasets_founded_list.append(all_datasets_founded) ##################\n",
    "        if len(datasets_founded_list) == 0 :\n",
    "            kagggle_dataset(f\"There is no {dataset_needed} \\n\\nEnter aonther dataset name!\")\n",
    "            return None\n",
    "        \n",
    "        index = all_datasets_founded_list.index(get_text_choise(all_datasets_founded_list,title=\"Kaggle database\"))\n",
    "        \n",
    "#       code to check if this string is path or not , and handeler if the path was not correct\n",
    "        selected_path = get_text_widget(\"Write your download path here!\")\n",
    "\n",
    "        dataset_founded = datasets_founded_list[index]\n",
    "        print(f'Downloading [{dataset_founded}] dataset')\n",
    "\n",
    "        dataset_content = api.dataset_list_files(str(dataset_founded)).files\n",
    "\n",
    "        api.dataset_download_files(str(dataset_founded) , selected_path)\n",
    "        \n",
    "        folder = get_text_choise([\"YES\",\"NO\"] , text = \"Do you want to open the directory of the downloaded file?\",title = \"Q!\")\n",
    "        if folder == \"YES\":\n",
    "            os.startfile(selected_path)\n",
    "        unzip_or_not = get_text_choise([\"YES\",\"NO\"] , text = \"Do you want to unzip the downloaded file?\",title = \"Q!\")\n",
    "        if unzip_or_not == \"YES\":\n",
    "            zip_file_location = get_full_path(selected_path , dataset_founded)\n",
    "            if unzip_file(selected_path , zip_file_location , dataset_founded):\n",
    "                get_message_box(\"Done unzipping successfully\")\n",
    "        \n",
    "    except:\n",
    "        print(\"ERROR404!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba732279",
   "metadata": {},
   "source": [
    "### Extracting downloaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e02746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(selected_path , zip_file_location , dataset_founded):\n",
    "    os.chdir(selected_path)\n",
    "    with zipfile.ZipFile(zip_file_location,'r') as file:\n",
    "        file.extractall(str(dataset_founded).split(\"/\")[-1])\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd7743",
   "metadata": {},
   "source": [
    "# Part 2 : Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188a3aa",
   "metadata": {},
   "source": [
    "### 1- Supervised machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490097e7",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "def logistic_regression(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model2 = LogisticRegression()\n",
    "    model2.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    train_pred = model2.predict(x_train_sc)\n",
    "    test_pred = model2.predict(x_test_sc)\n",
    "\n",
    "    train_score = metrics.accuracy_score( train_pred , y_train_sc )\n",
    "    test_score = metrics.accuracy_score( test_pred , y_test_sc )\n",
    "\n",
    "    logistic_regression_score = f\"{'Logistic regression score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "#     scores[\"Logistic_regression\"] = Logistic_regression\n",
    "\n",
    "    return logistic_regression_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fff2b",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a65f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    predict = model.predict(x_test_sc)\n",
    "    \n",
    "    train_score = model.score(x_train_sc , y_train_sc) \n",
    "    test_score = model.score(x_test_sc , y_test_sc) \n",
    "    logistic_regression_score = f\"{'Logistic regression score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return logistic_regression_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263d6d8",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3afe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn import metrics\n",
    "\n",
    "def k_neighbor(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model3 = KNeighborsClassifier()\n",
    "    model3.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    tr_pred = model3.predict(x_train_sc)\n",
    "    te_pred = model3.predict(x_test_sc)\n",
    "\n",
    "    train_score = metrics.accuracy_score(tr_pred,y_train_sc)\n",
    "    test_score = metrics.accuracy_score(te_pred,y_test_sc)\n",
    "\n",
    "    knn_score = f\"{'KNeighbors score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "#     scores[\"KNN_score\"] = KNN_score\n",
    "    \n",
    "    return knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f41c1",
   "metadata": {},
   "source": [
    "#### Decisiond tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16c18afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decisiond_tree(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    \n",
    "    model4 = DecisionTreeClassifier( max_depth = 3)\n",
    "    model4.fit(x_train,y_train)\n",
    "\n",
    "    train_score = model4.score( x_train , y_train )\n",
    "    test_score = model4.score( x_test , y_test )\n",
    "\n",
    "    decision_tree_score = f\"{'Decision tree score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    # scores[\"decision_tree_score\"] = decision_tree_score\n",
    "    \n",
    "    return decision_tree_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e54ce",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42782a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def neural_network(x_train,x_test, y_train, y_test):\n",
    "    model5 = MLPClassifier(activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='constant',\n",
    "                                       early_stopping=False,\n",
    "                                       alpha=0.001, hidden_layer_sizes=(100, 3), random_state = 33)\n",
    "    model5.fit(x_train, y_train)\n",
    "\n",
    "    train_score = model5.score(x_train, y_train)\n",
    "    test_score = model5.score(x_test, y_test)\n",
    "\n",
    "    neural_network_score = f\"{'Neural network score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    # scores[\"neural_network_score\"] = neural_network_score\n",
    "    return neural_network_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9d9a3",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c92ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def svm(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    \n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                  'kernel': ['rbf'] }\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid)\n",
    "    grid.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    ###################################################\n",
    "\n",
    "    grid_predictions = grid.predict(x_test_sc)\n",
    "    metrics.accuracy_score(grid_predictions,y_test_sc)\n",
    "\n",
    "    ##################################################\n",
    "\n",
    "    model6 = SVC()\n",
    "    model6.fit(x_train_sc, y_train_sc)\n",
    "\n",
    "    train_predictions = model6.predict(x_train_sc)\n",
    "    test_predictions = model6.predict(x_test_sc)\n",
    "\n",
    "    model6.get_params()\n",
    "\n",
    "    train_score = metrics.accuracy_score(train_predictions,y_train_sc) \n",
    "    test_score = metrics.accuracy_score(test_predictions,y_test_sc)\n",
    "\n",
    "    svm_score = f\"{'SVM score'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return svm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6ed4e",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8646bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def random_forest(x_train_sc , x_test_sc , y_train_sc , y_test_sc):\n",
    "    model7 = RandomForestClassifier(n_estimators = 20 , random_state = 30)\n",
    "    model7.fit(x_train_sc,y_train_sc)\n",
    "\n",
    "    prediction_test = model7.predict(x_test_sc)\n",
    "    test_score = metrics.accuracy_score(y_test_sc, prediction_test)\n",
    "\n",
    "    random_forest = f\"{'Random forest'.center(25)} | {'Train score'.center(15)} -> ------% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "#     scores[\"random_forest\"] = random_forest\n",
    "\n",
    "#     feature_list = list(x.columns)\n",
    "#     feature_imp = pd.Series(model7.feature_importances_,index=feature_list).sort_values(ascending=False)\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a6f0d",
   "metadata": {},
   "source": [
    "#### Naive baise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4ab906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_baise(x_train,x_test, y_train, y_test):\n",
    "    model8 = GaussianNB()\n",
    "    model8.fit(x_train,y_train)\n",
    "\n",
    "    train_score = model8.score(x_train , y_train)\n",
    "    test_score = model8.score(x_test , y_test)\n",
    "\n",
    "    naive_baise_score = f\"{'Naive baise'.center(25)} | {'Train score'.center(15)} -> {round(train_score * 100,3)}% {'Test score'.center(15)} -> {round(test_score * 100,3)}%\"\n",
    "    return naive_baise_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee702b",
   "metadata": {},
   "source": [
    "### Unsupervised machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d820143",
   "metadata": {},
   "source": [
    "#### Clustring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcedc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af2a5f",
   "metadata": {},
   "source": [
    "#### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2a2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888f240",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd72b5",
   "metadata": {},
   "source": [
    "#### Create your data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b16cd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your csv file to create the dataframe directly , If you have not any data frame ready to be used this \n",
    "counter = 1\n",
    "data_frame = None\n",
    "def load_data_frame():\n",
    "    try:\n",
    "        global data_frame\n",
    "        data_frame = get_data_frame()\n",
    "        return True\n",
    "    except:\n",
    "        global counter\n",
    "        if counter <= 3:\n",
    "            counter += 1\n",
    "            get_message_box(\"Please select olny preproccessed csv file to avoid errors!\")\n",
    "            load_data_frame()\n",
    "        else:\n",
    "            get_message_box(\"You were warned to select only csv files :) \")\n",
    "            return False\n",
    "# We calculate how many you will choose the wrong file, \n",
    "# so that I can close the program so that it does not fall into infinity loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "818dbec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():    \n",
    "    items =[\n",
    "    \"Download kaggle dataset\",\n",
    "    \"Use machine learning models\"\n",
    "    ]\n",
    "\n",
    "    item = get_text_choise(choices = items)\n",
    "    \n",
    "    if item == \"Download kaggle dataset\":\n",
    "        kagggle_dataset()\n",
    "    elif item == \"Use machine learning models\":\n",
    "        ml_type = get_text_choise(choices=[\"Supervised\",\"Unsupervised\",\"Back\"])\n",
    "        if ml_type == \"Supervised\":\n",
    "#           Check if the user will predict a continous value or descrete to decide what algorithms will be used!\n",
    "            supervised_models_list = [\n",
    "                \"Logistic regression\",\n",
    "                \"Linear regression\",\n",
    "                \"KNN\",\n",
    "                \"Decisiond tree\",\n",
    "                \"Neural network\",\n",
    "                \"SVM\",\n",
    "                \"Random forest\",\n",
    "                \"Naive baise\",\n",
    "                \"All models\",\n",
    "                \"Back\"\n",
    "            ]\n",
    "            supervised_model = get_text_choise(supervised_models_list)\n",
    "            \n",
    "            y = data_frame[data_frame.columns[-1]]\n",
    "            x = data_frame.drop(data_frame.columns[-1],axis=1)\n",
    "            \n",
    "            x_train , x_test , y_train , y_test = get_splitted_data(x,y)\n",
    "            \n",
    "            x = get_scaled_data(x)\n",
    "            \n",
    "            x_trainsc , x_testsc , y_trainsc , y_testsc = get_splitted_data(x,y)\n",
    "            \n",
    "            try:\n",
    "                index_of_model = supervised_models_list.index(supervised_model)\n",
    "                print(\"index_of_model\",index_of_model)\n",
    "                if index_of_model == 0:\n",
    "                    score = logistic_regression(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 1:\n",
    "                    score = linear_regression(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 2:\n",
    "                    score = k_neighbor(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 3:\n",
    "                    score = decisiond_tree(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 4:\n",
    "                    score = neural_network(x_train , x_test , y_train , y_test)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 5:\n",
    "                    score = svm(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 6:\n",
    "                    score = random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 7:\n",
    "                    score = naive_baise(x_train , x_test , y_train , y_test)\n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model == 8:\n",
    "#                     All accuracy\n",
    "\n",
    "                    score = logistic_regression(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += linear_regression(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += k_neighbor(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += decisiond_tree(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += neural_network(x_train , x_test , y_train , y_test) + \"\\n\"\n",
    "                    score += svm(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += random_forest(x_trainsc , x_testsc , y_trainsc , y_testsc) + \"\\n\"\n",
    "                    score += naive_baise(x_train , x_test , y_train , y_test)\n",
    "                    print(score)\n",
    "                    \n",
    "#                     Concatination in jupyter does not work!!!!!!\n",
    "                    \n",
    "                    get_message_box(score)\n",
    "                    run()\n",
    "                    return None\n",
    "                elif index_of_model ==10:\n",
    "                    run()\n",
    "                    return None\n",
    "                else:\n",
    "                    get_message_box(\"The program will be closed :) \")\n",
    "                    sys.exit()\n",
    "                \n",
    "            except:\n",
    "#                 If any errors happened then the user closed the window , so we're gonna close the programe\n",
    "                exit()                \n",
    "        elif ml_type == \"Unsupervised\":\n",
    "            unsupervised_models_list = [\n",
    "                \"No models avilable now\",\n",
    "                \"Back\"\n",
    "            ]\n",
    "            unsupervised_model = get_text_choise(unsupervised_models_list)\n",
    "        elif ml_type == \"Back\":\n",
    "            run()\n",
    "            return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097fa0d",
   "metadata": {},
   "source": [
    "#### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc6628d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR404!\n"
     ]
    }
   ],
   "source": [
    "if (load_data_frame()):\n",
    "    run()\n",
    "else:\n",
    "    get_message_box(\"The program will be closed :) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed97bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b82b940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac6099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edd03367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enginner Asmaa csv file\n",
    "\n",
    "# data_frame = pd.read_csv(\"diabetes.csv\")\n",
    "# y = data_frame[\"Outcome\"]\n",
    "# x = data_frame.drop(\"Outcome\",axis=1)\n",
    "\n",
    "# # Before scaling\n",
    "\n",
    "# x_train , x_test , y_train , y_test = get_splitted_data(x,y)\n",
    "\n",
    "# print(logistic_regression(x_train , x_test , y_train , y_test))\n",
    "# print(linear_regression(x_train , x_test , y_train , y_test))\n",
    "# print(k_neighbor(x_train , x_test , y_train , y_test))\n",
    "# print(decisiond_tree(x_train , x_test , y_train , y_test))\n",
    "# print(neural_network(x_train , x_test , y_train , y_test))\n",
    "# print(svm(x_train , x_test , y_train , y_test))\n",
    "# print(random_forest(x_train , x_test , y_train , y_test))\n",
    "# print(naive_baise(x_train , x_test , y_train , y_test))\n",
    "\n",
    "\n",
    "# print(120*\"-\")\n",
    "\n",
    "# After scaling\n",
    "\n",
    "# x = get_scaled_data(x)\n",
    "\n",
    "# x_trainsc , x_testsc , y_trainsc , y_testsc = get_splitted_data(x,y)\n",
    "\n",
    "# print(logistic_regression(x_train , x_test , y_train , y_test))\n",
    "# print(linear_regression(x_train , x_test , y_train , y_test))\n",
    "# print(k_neighbor(x_train , x_test , y_train , y_test))\n",
    "# print(decisiond_tree(x_train , x_test , y_train , y_test))\n",
    "# print(neural_network(x_train , x_test , y_train , y_test))\n",
    "# print(svm(x_train , x_test , y_train , y_test))\n",
    "# print(random_forest(x_train , x_test , y_train , y_test))\n",
    "# print(naive_baise(x_train , x_test , y_train , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48450af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5343ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e947449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Engineer Rawan csv file \n",
    "\n",
    "# data_frame = pd.read_csv(\"titanic400.csv\")\n",
    "# data_frame.drop(columns=[\"Name\",\"PassengerId\",\"Cabin\",\"Ticket\",\"Parch\",\"Embarked\",\"SibSp\"],inplace=True)\n",
    "# data_frame[\"Age\"].fillna(data_frame[\"Age\"].mean(),inplace=True)\n",
    "# data_frame[\"Sex\"].replace({ \"female\":0 , \"male\":1 } , inplace=True)\n",
    "# data_frame.dropna(axis=\"index\",how=\"any\",inplace=True)\n",
    "\n",
    "# x = data_frame.drop([\"Survived\"] , axis = 1)\n",
    "# y = data_frame['Survived']\n",
    "\n",
    "\n",
    "# x_train , x_test , y_train , y_test = get_splitted_data(x,y)\n",
    "\n",
    "# print(logistic_regression(x_train , x_test , y_train , y_test))\n",
    "# print(linear_regression(x_train , x_test , y_train , y_test))\n",
    "# print(k_neighbor(x_train , x_test , y_train , y_test))\n",
    "# print(decisiond_tree(x_train , x_test , y_train , y_test))\n",
    "# print(neural_network(x_train , x_test , y_train , y_test))\n",
    "# print(svm(x_train , x_test , y_train , y_test))\n",
    "# print(random_forest(x_train , x_test , y_train , y_test))\n",
    "# print(naive_baise(x_train , x_test , y_train , y_test))\n",
    "\n",
    "\n",
    "\n",
    "# x = get_scaled_data(x)\n",
    "\n",
    "\n",
    "# # After scaling\n",
    "\n",
    "# x_trainsc , x_testsc , y_trainsc , y_testsc = get_splitted_data(x,y)\n",
    "\n",
    "# print(logistic_regression(x_train , x_test , y_train , y_test))\n",
    "# print(linear_regression(x_train , x_test , y_train , y_test))\n",
    "# print(k_neighbor(x_train , x_test , y_train , y_test))\n",
    "# print(decisiond_tree(x_train , x_test , y_train , y_test))\n",
    "# print(neural_network(x_train , x_test , y_train , y_test))\n",
    "# print(svm(x_train , x_test , y_train , y_test))\n",
    "# print(random_forest(x_train , x_test , y_train , y_test))\n",
    "# print(naive_baise(x_train , x_test , y_train , y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad379638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4385c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I saved this file after preproccessing to test the code \n",
    "\n",
    "# # This is Engineer Rawan file\n",
    "\n",
    "# data_frame = pd.read_csv(\"titanic400.csv\")\n",
    "# data_frame.drop(columns=[\"Name\",\"PassengerId\",\"Cabin\",\"Ticket\",\"Parch\",\"Embarked\",\"SibSp\"],inplace=True)\n",
    "# data_frame[\"Age\"].fillna(data_frame[\"Age\"].mean(),inplace=True)\n",
    "# data_frame[\"Sex\"].replace({ \"female\":0 , \"male\":1 } , inplace=True)\n",
    "# data_frame.dropna(axis=\"index\",how=\"any\",inplace=True)\n",
    "# kk = data_frame[\"Survived\"]\n",
    "# data_frame.drop(\"Survived\",axis=1,inplace=True)\n",
    "# data_frame[\"Survived\"] = kk\n",
    "# data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cd46859",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  save csv file\n",
    "# data_frame.to_csv(\"E:\\Courses\\IEEE\\preproccessed_titanic.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
